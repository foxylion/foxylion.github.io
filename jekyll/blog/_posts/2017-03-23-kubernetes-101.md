---
layout: post
title:  "Kubernetes 101 - A working introduction to Kubernetes"
date:   2017-03-23 12:00:00 +0000
permalink: /blog/kubernetes-101/
---

This is a pretty long article trying to cover an introduction to Kubernetes in
dept. The table of contents should give an overview what is contained.

### Table of contents
{: .no_toc}

* TOC
{:toc}

### Required prior knowledge

This guide does have some requirements about concepts which should be learned before.

**Containers**: Today everyone wants to run services in containers, you should have a basic understanding what this is all about and why you would want this. If you are not familiar with containers. Have a look [here](https://docs.docker.com/engine/understanding-docker/). In general it is recommended to get started with containers before thinking about rolling out Kubernetes.

**Service oriented architecture**: Kubernetes solves mostly problems introduced by systems with many moving parts. A service oriented architecture tries to modularize a big application into multiple smaller parts which use well defined interfaces to interact with each other. The interaction is what Kubernetes will help you with. Today most would consider a microservice architecture as the state of the art. Martin Fowler wrote a [very good article](https://martinfowler.com/articles/microservices.html) about this.

**Orchestration**: The orchestration concept defines some terms like service discovery, scalability, high availability. You should know why you want this. More details [here](#link-missing).

There are many more things which may be important to know but not described in the article. I tried to link as much as possible so you should always find a good article which is going more into dept. I would recommend to read everything and later click on all those links. If something is missing I would appreciate it when you contact me and I will try to improve this as much as possible.

### Reasons to use Kubernetes

Someone familiar with containers will be pretty amazed about the simplicity of packaging a service into a shippable format. But running this in a highly available and scalable manner is another story which is not solved by simply using containers.

Kubernetes is a system for automating deployment, scaling, and management of containers containing your application. It will also provide you a self-healing system which can recovery automatically from failures like a server failure. Additionally it provides integrated service discovery, load balancing and configuration management.

### General terms used in Kubernetes

Kubernetes is a world full of things you may have never heard before. This section should give you a brief overview what you should associate with the most common terms.

A [**Cluster**] describes the system as a whole. A cluster contains several nodes and one or multiple masters.

A [**Master**] is the management unit of the cluster. It hosts a scheduler which is responsible for starting and stopping pods in the cluster.

A [**Node**] is a server which joined the cluster and is available to host pods scheduled by the master.

A [**Pod**] is a unit which is being scheduled inside your cluster. In general you can replace it with "a group of containers". Normally you would only want to group a single container into a pod. Use cases for a second container in a pod could be a separate health check process or a background task syncing data used by the main container.

A [**Service**] allows addressing of a single group of pods inside the cluster. You would use this to prevent direct addressing of a single pod (which is something you rarely would do, as this breaks scaling and high availability).

A [**NodePort**] is a port which is opened on each node and forwards traffic to a specified service.

A [**Replica**] is one of multiple running running pods with the same configuration.

A [**ReplicaSet**] is a configuration to define the schedule of a defined amount of pods inside the cluster. This can be a single instance of a pod or with hundreds of replicas. It also contains the configuration of the pod (e.g. image name, environment variables or health checks).

A [**Deployment**] is an extended version of the replica set, it additionally defines how updates are done (e.g. a rolling update). Normally you only use deployments. Internally a deployment generates a replica set to actually schedule the pods.

A [**DaemonSet**] is like a replication set but instead of defining specific amount of pods it defines to create a pod on each node of the cluster. This can be useful when you want to forward things from each node to a central location (e.g. logs).

A [**ConfigMap**] is more or less a configuration file which can be access by various components inside the cluster (e.g. environment variables for a pod).

A [**Secret**] is a more or less protected config map used to store secret values which should later be passed into pods (e.g. credentials for the database). The secrets are not stored encrypted but are protected to be accidentally displayed (by default they are erased from output of the command line tool).

A [**Ingress**] is a rule set to direct traffic from a source (normally from the outside) in the cluster to a specified service. So a rule could be for example forward all traffic of `guestbook.mywebshop.com` to the service `guestbook`.

A [**Label**] is a annotation a resource, it can later be used to identify a specific set of resources. This can be for example a label `guestbook` which is assigned to all pods running a guestbook container. Then a service can be configured to forward all requests to pods labeled with `guestbook`.

There are several more terms used inside Kubernetes, but these should be enough to understand the basic concepts of Kubernetes.

### Kubernetes behind the scenes

Behind the scenes Kubernetes does a lot allow the transparent scheduling of containers inside your cluster. It is important to get a rough overview what Kubernetes is doing in case something went wrong.

Kubernetes internally assigns each pod a unique IP address. This address can be used to communicate with the pod. All containers inside the pod share the same IP address so they share the same ports. This simplifies communication inside the pod, but you must ensure that no port is bound twice. But you may recall - normally we would only use one container per pod.

Kubernetes is aware which container is on which node and would forward any requests to a pod on another host using [iptables](https://en.wikipedia.org/wiki/Iptables). In general, most simple routing is done using iptables rules. The component responsible to get this working is called [`kube-proxy`](https://kubernetes.io/docs/admin/kube-proxy/).

Services inside the cluster are just rules in iptables created by `kube-proxy`. So services are a lightweight load balancing when multiple pods are behind a service.

Since accessing pods or services using their IP addresses is not straight forward Kubernetes is normally combined with a component called [`kube-dns`](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/). This will provide dns records for each service and pod inside the cluster. They are normally derived from their names. This allows a simple service discovery inside the cluster.

On the master server(s) there is a scheduler [`kube-scheduler`](https://kubernetes.io/docs/admin/kube-scheduler/) which is responsible for the scheduling of the correct amount of pods on the nodes inside the cluster. It considers available and required resources and then plans where a new pod can be launched.

The container lifecycle is managed by a component called [`kubelet`](https://kubernetes.io/docs/admin/kubelet/). One kubelet is running on each node in the cluster. It manages the containers running on a node and reports back health information about the containers.

Kubernetes stores all the configuration and state of your cluster inside and [etcd store](https://github.com/coreos/etcd/tree/master/Documentation). This store is normally [highly available](https://github.com/coreos/etcd/blob/master/Documentation/op-guide/clustering.md). Otherwise your cluster could not reschedule any pods in case of an etcd outage.

To interact with a Kubernetes cluster we need a API that allows retrieving the current state and issuing modification requests. In Kubernetes this is the [`kube-apiserver`](https://kubernetes.io/docs/admin/kube-apiserver/). It exposes an API which can be accessed from inside the cluster and normally from outside with tools like [`kubectl`](https://kubernetes.io/docs/user-guide/kubectl-overview/).

Most of the Kubernetes components run themselves in the cluster. This gives the controlling components of Kubernetes the same advantages like the application deployed in the cluster.

### Kubernetes in a diagram

After all these definitions and "behind the scenes" we should now have a rough understanding of all the components inside our cluster. The following diagrams are trying to visualize this one more time.

If there are is something too difficult it may help to first read on (especially in the communication diagrams).

**Pods on our servers inside the cluster**
![image](/blog/kubernetes-101/nodes.svg)

As you can see, some of the Kubernetes components are only running on the master server. Other (like dns) are also scheduled on the nodes. Also there is a difference in how the website is scheduled in comparison to the webshop or guestbook (one vs. two replicas).


**Communication inside the cluster**
![image](/blog/kubernetes-101/communication-inside.svg)

Inside the cluster it is possible to either directly communicate with a pod (by knowing its IP or DNS name) or use a service which resolves to a group of pods serving the same part of the application. This could be for example be an API to retrieve the newest articles in the shop to be displayed on the website. Or the webshop accessing the database containing all articles.

**Communication into the cluster**
![image](/blog/kubernetes-101/communication-outside.svg)

We accessing the cluster from outside using a specified `NodePort`. This forwards all traffic to a specified service. In this case this is a `ingress-controller`. Which routes the traffic based on the defined `Ingress` rules to the matching services or pods (this depends on the controller). More details how this works will follow.
